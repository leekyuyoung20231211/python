{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pquNMcnfrHxl"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "합성곱 GAN 과 바서슈타인 GAN 으로 합성 이미지 품질 높이기"
      ],
      "metadata": {
        "id": "dCaQrcxMtkIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url='https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch17/figures/17_09.png', width=700)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "L6kW-tKrtisI",
        "outputId": "2d062dcb-677b-49d2-e115-d83f053ea763"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch17/figures/17_09.png\" width=\"700\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "배치정규화"
      ],
      "metadata": {
        "id": "0TA89mv-tiuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url='https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch17/figures/17_11.png', width=700)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "MZC8QWD6tiw3",
        "outputId": "1498fb3b-0d41-4f15-a26d-b14905227049"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch17/figures/17_11.png\" width=\"700\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "생성자와 판별자"
      ],
      "metadata": {
        "id": "rtB9iqNWtizO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url='https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch17/figures/17_12.png', width=700)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "qFy8TPhfti1d",
        "outputId": "1017dffc-4ea8-4d38-ca0c-6df1139ef530"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch17/figures/17_12.png\" width=\"700\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url='https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch17/figures/17_13.png', width=700)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "kaDf26KFti30",
        "outputId": "38662c6f-11e6-498b-f589-4cb67c6cd225"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch17/figures/17_13.png\" width=\"700\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "POKq8NBfti6L",
        "outputId": "3bb10488-f8a5-4e83-8abd-86235cffad01"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "-IzcpxVgti8V"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "x3C3agu2ti-Z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "image_path = './'\n",
        "transfom = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5), std=(0.5))\n",
        "])\n",
        "\n",
        "mnist_dataset = torchvision.datasets.MNIST(root=image_path, train=True, transform=transfom,download=True)\n",
        "\n",
        "batch_size = 64\n",
        "torch.manual_seed(1)\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "mnist_dl = DataLoader(mnist_dataset, batch_size=batch_size,shuffle=True,drop_last=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpYfFiXvtjC4",
        "outputId": "4885cbfa-7355-49e6-b763-e2680986e377"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 158567297.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 30505085.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 59042057.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 22281320.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_generator_network(input_size, n_filters):\n",
        "  model = nn.Sequential(\n",
        "      nn.ConvTranspose2d(input_size, n_filters*4, 4,1,0,bias=False),\n",
        "      nn.BatchNorm2d(n_filters*4),\n",
        "      nn.LeakyReLU(0.2),\n",
        "\n",
        "      nn.ConvTranspose2d(n_filters*4, n_filters*2,3,2,1,bias=False),\n",
        "      nn.BatchNorm2d(n_filters*2),\n",
        "      nn.LeakyReLU(0.2),\n",
        "\n",
        "      nn.ConvTranspose2d(n_filters*2, n_filters,4,2,1,bias=False),\n",
        "      nn.BatchNorm2d(n_filters),\n",
        "      nn.LeakyReLU(0.2),\n",
        "\n",
        "      nn.ConvTranspose2d(n_filters, 1,4,2,1, bias=False),\n",
        "      nn.Tanh()\n",
        "  )\n",
        "  return model\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self,n_filters):\n",
        "    super().__init__()\n",
        "    self.network = nn.Sequential(\n",
        "        nn.Conv2d(1,n_filters, 4,2,1,bias=False),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(n_filters, n_filters*2,4,2,1, bias=False),\n",
        "        nn.BatchNorm2d(n_filters*2),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(n_filters*2, n_filters*4,3,2,1, bias=False),\n",
        "        nn.BatchNorm2d(n_filters*4),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(n_filters*4,1,4,1,0,bias=False),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self, input):\n",
        "    output = self.network(input)\n",
        "    return output.view(-1,1).squeeze(0)"
      ],
      "metadata": {
        "id": "H0OLBQw8wNtv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z_size = 100\n",
        "image_size = (28,28)\n",
        "n_filters = 32\n",
        "gen_model = make_generator_network(z_size, n_filters).to(device)\n",
        "print(gen_model)\n",
        "disc_model = Discriminator(n_filters).to(device)\n",
        "print(disc_model)"
      ],
      "metadata": {
        "id": "LdCR_eLb10b6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실함수와 옵티마이져\n",
        "loss_fn = nn.BCELoss()\n",
        "g_optimizer = torch.optim.Adam(gen_model.parameters(),0.0003)\n",
        "d_optimizer = torch.optim.Adam(disc_model.parameters(), 0.0002)"
      ],
      "metadata": {
        "id": "2WgeVZSy2Kva"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_noise(batch_size, z_size,mode_z):\n",
        "  if mode_z == 'uniform':\n",
        "    input_z = torch.rand(batch_size, z_size,1,1)*2 - 1\n",
        "  elif mode_z == 'normal':\n",
        "    input_z = torch.randn(batch_size, z_size,1,1)\n",
        "  return input_z"
      ],
      "metadata": {
        "id": "JhLMGCTE2taW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 판별자 훈련\n",
        "def d_train(x):\n",
        "  disc_model.zero_grad()\n",
        "    # 진짜 배치에서 판별자 훈련\n",
        "  batch_size = x.size(0)\n",
        "  x = x.to(device)\n",
        "  d_labels_real = torch.ones(batch_size, 1, device=device)\n",
        "\n",
        "  d_proba_real = disc_model(x)\n",
        "  d_loss_real = loss_fn(d_proba_real, d_labels_real)\n",
        "\n",
        "  # 가짜 배치에서 판별자 훈련\n",
        "  input_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
        "  g_output = gen_model(input_z)\n",
        "\n",
        "  d_proba_fake = disc_model(g_output)\n",
        "  d_labels_fake = torch.zeros(batch_size, 1, device=device)\n",
        "  d_loss_fake = loss_fn(d_proba_fake, d_labels_fake)\n",
        "\n",
        "  # 그레이디언트 역전파와 판별자 파라미터 최적화\n",
        "  d_loss = d_loss_real + d_loss_fake\n",
        "  d_loss.backward()\n",
        "  d_optimizer.step()\n",
        "\n",
        "  return d_loss.data.item(), d_proba_real.detach(), d_proba_fake.detach()"
      ],
      "metadata": {
        "id": "J5p8oiqK3Ggo"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.ones((batch_size,1),device=device)"
      ],
      "metadata": {
        "id": "54CNctREBc9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 생성자 훈련\n",
        "def g_train(x):\n",
        "  gen_model.zero_grad()\n",
        "  batch_size = x.size(0)\n",
        "  input_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
        "  g_labels_real = torch.ones((batch_size,1),device=device)\n",
        "\n",
        "  g_output = gen_model(input_z)\n",
        "  d_proba_fake = disc_model(g_output)\n",
        "  g_loss = loss_fn(d_proba_fake, g_labels_real)\n",
        "\n",
        "  # 그레이디언트 역전파와 생성자 파라미터 최적화\n",
        "  g_loss.backward()\n",
        "  g_optimizer.step()\n",
        "\n",
        "  return g_loss.data.item()"
      ],
      "metadata": {
        "id": "PnE_gwTu44lv"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mode_z = 'uniform'\n",
        "fixed_z = create_noise(batch_size,z_size,mode_z).to(device)\n",
        "def create_samples(g_model, input_z):\n",
        "  g_output = g_model(input_z)\n",
        "  images = torch.reshape(g_output, (batch_size, *image_size))\n",
        "  return (images+1) / 2.0\n",
        "\n",
        "epoch_samples = []\n",
        "num_epochs = 100\n",
        "torch.manual_seed(1)\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "  gen_model.train()\n",
        "  d_losses, g_losses = [],[]\n",
        "  for i, (x, _) in enumerate(mnist_dl):\n",
        "    d_loss, d_proba_real, d_proba_fake = d_train(x)\n",
        "    d_losses.append(d_loss)\n",
        "    g_losses.append(g_train(x))\n",
        "\n",
        "  print(f'에포크 {epoch:03d} | 평균 손실 >>'\n",
        "        f' 생성자/판별자 {torch.FloatTensor(g_losses).mean():.4f}'\n",
        "        f'/{torch.FloatTensor(d_losses).mean():.4f}')\n",
        "  gen_model.eval()\n",
        "  epoch_samples.append(\n",
        "      create_samples(gen_model, fixed_z).detach().cpu().numpy()\n",
        "  )"
      ],
      "metadata": {
        "id": "popAigHo5kWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시각화를 위해서 수집한 변수를 저장하고 불러오기\n",
        "saved_variables = {\n",
        "    'epoch_samples': epoch_samples,\n",
        "    'd_losses': d_losses,\n",
        "    'g_losses': g_losses\n",
        "}\n",
        "torch.save(saved_variables,'/content/drive/MyDrive/saved_variables2,pth')\n",
        "\n",
        "\n",
        "# 판별자 모델\n",
        "torch.save(disc_model,'/content/drive/MyDrive/disc_model2.pth')\n",
        " # 생성자 모델\n",
        "torch.save(gen_model,'/content/drive/MyDrive/gen_model2.pth')"
      ],
      "metadata": {
        "id": "Z7zKDfdS7EPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"device : {device}\")\n",
        "\n",
        "# 불러오기\n",
        "loaded_variables = torch.load('/content/drive/MyDrive/saved_variables2,pth')\n",
        "# 각 변수를 불러오기\n",
        "epoch_samples = loaded_variables['epoch_samples']\n",
        "d_losses = loaded_variables['d_losses']\n",
        "g_losses = loaded_variables['g_losses']\n",
        "# 판별자 생성자 모델 불러오기\n",
        "disc_model = torch.load('/content/drive/MyDrive/disc_model2.pth')\n",
        "gen_model = torch.load('/content/drive/MyDrive/gen_model2.pth')"
      ],
      "metadata": {
        "id": "q4Se88q1CS3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "udWT-EwpC0T1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
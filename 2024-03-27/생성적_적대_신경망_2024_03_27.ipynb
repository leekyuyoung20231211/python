{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pquNMcnfrHxl"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "목차\n",
        "\n",
        "\n",
        "* 생성적 적대 신경망 소개\n",
        "    * 오토인코더\n",
        "    * 새로운 데이터 합성을 위한 생성 모델\n",
        "    * GAN으로 새로운 샘플 생성\n",
        "    * GAN의 생성자와 판별자 손실 함수 이해\n",
        "\n",
        "* 밑바닥부터 GAN 모델 구현\n",
        "    * 구글 코랩에서 GAN 모델 훈련\n",
        "    * 생성자와 판별자 신경망 구현\n",
        "    * 훈련 데이터셋 정의\n",
        "    * GAN 모델 훈련하기"
      ],
      "metadata": {
        "id": "C89w739trPhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 오토 인코더\n",
        "Image(url='https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch17/figures/17_01.png', width=400)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "9NlduGIYrtx0",
        "outputId": "d309a664-1079-465b-ae38-3415a22ca1c7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch17/figures/17_01.png\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 데이터 합성을 위한 생성모델\n",
        "Image(url='https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch17/figures/17_02.png', width=700)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "p7ldkeATr4pe",
        "outputId": "4e6f6f56-063b-4f88-8435-6dd41bc0e88d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch17/figures/17_02.png\" width=\"700\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url='https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch17/figures/17_03.png', width=700)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "dBLMQ5udsZRD",
        "outputId": "30539a60-86da-49ca-810f-33a7cb87af17"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch17/figures/17_03.png\" width=\"700\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ti1XEUU7s4Pb",
        "outputId": "3105f21c-cb72-4534-b9c3-446bc30f5b71"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "9wZw81FJtR4G"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 생성자 함수 정의\n",
        "def make_generator_network(\n",
        "    input_size=20, num_hidden_layers = 1, num_hidden_units=100,num_output_units=784\n",
        "):\n",
        "  model = nn.Sequential()\n",
        "  for i in range(num_hidden_layers):\n",
        "    model.add_module(f'fc_g{i}', nn.Linear(input_size, num_hidden_units) )\n",
        "    model.add_module(f'relu_g{i}', nn.LeakyReLU())\n",
        "    input_size = num_hidden_units\n",
        "  model.add_module(f'fc_g{num_hidden_layers}', nn.Linear(input_size, num_output_units) )\n",
        "  model.add_module('tanh_g', nn.Tanh())\n",
        "  return model\n",
        "\n",
        "def make_discriminator_network(\n",
        "    input_size, num_hidden_layers = 1, num_hidden_units=100,num_output_units=1\n",
        "):\n",
        "  model = nn.Sequential()\n",
        "  for i in range(num_hidden_layers):\n",
        "    model.add_module(f'fc_d{i}', nn.Linear(input_size, num_hidden_units, bias=False) )\n",
        "    model.add_module(f'relu_d{i}', nn.LeakyReLU())\n",
        "    model.add_module('dropout', nn.Dropout(p=0.5))\n",
        "    input_size = num_hidden_units\n",
        "  model.add_module(f'fc_d{num_hidden_layers}', nn.Linear(input_size, num_output_units) )\n",
        "  model.add_module('sigmoid', nn.Sigmoid())\n",
        "  return model"
      ],
      "metadata": {
        "id": "wvEufFWTtuA1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (28,28)\n",
        "z_size = 20\n",
        "\n",
        "gen_hidden_layers = 1\n",
        "gen_hidden_size = 100\n",
        "disc_hidden_layers = 1\n",
        "disc_hidden_size = 100\n",
        "torch.manual_seed(1)\n",
        "\n",
        "params = {\n",
        "    'input_size':z_size,'num_hidden_layers':gen_hidden_layers,\n",
        "    'num_hidden_units':gen_hidden_size,'num_output_units':np.prod(image_size)\n",
        "}\n",
        "\n",
        "gen_model = make_generator_network(**params)\n",
        "gen_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5kx_UIev_Jh",
        "outputId": "8778d673-3ded-4d16-a486-2e5abc64ad63"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (fc_g0): Linear(in_features=20, out_features=100, bias=True)\n",
              "  (relu_g0): LeakyReLU(negative_slope=0.01)\n",
              "  (fc_g1): Linear(in_features=100, out_features=784, bias=True)\n",
              "  (tanh_g): Tanh()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params={\n",
        "    'input_size':np.prod(image_size), 'num_hidden_layers':disc_hidden_layers,\n",
        "    'num_hidden_units':disc_hidden_size\n",
        "}\n",
        "disc_model = make_discriminator_network(**params)\n",
        "disc_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Du7XYJKEw-nA",
        "outputId": "5c3de033-89a2-4ef6-f7f3-911b8fc79e2c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (fc_d0): Linear(in_features=784, out_features=100, bias=False)\n",
              "  (relu_d0): LeakyReLU(negative_slope=0.01)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc_d1): Linear(in_features=100, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터 셋 정의\n",
        "import torchvision\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "5jdCXxpRxY-N"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = './'\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5), std=(0.5))\n",
        "])\n",
        "mnist_dataset = torchvision.datasets.MNIST(\n",
        "    root = image_path, train=True, transform = transform,download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ni-SEX-GxiRZ",
        "outputId": "b0d83284-2991-4270-818f-67b6a2e3f63a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 145003056.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 18824505.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 46287079.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 20550732.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example, label =  next(iter(mnist_dataset))\n",
        "print(f'최소 : {example.min()} 최대:{example.max()}')\n",
        "print(example.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iojiAwiHyF6P",
        "outputId": "407f4aff-ac9f-4cd9-ae34-5f8d8f14f1c0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최소 : -1.0 최대:1.0\n",
            "torch.Size([1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_noise(batch_size, z_size, mode_z):\n",
        "  if mode_z == 'uniform':\n",
        "    input_z = torch.rand(batch_size, z_size)*2 - 1\n",
        "  elif mode_z =='normal':\n",
        "    input_z = torch.randn(batch_size, z_size)\n",
        "  return input_z"
      ],
      "metadata": {
        "id": "biGdyZSiyoMa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size = 32\n",
        "dataloader = DataLoader(mnist_dataset, batch_size, shuffle=True)\n",
        "input_real, label =  next(iter(dataloader))\n",
        "input_real = input_real.view(batch_size, -1)\n",
        "\n",
        "torch.manual_seed(1)\n",
        "mode_z = 'uniform'\n",
        "input_z  = create_noise(batch_size, z_size, mode_z)\n",
        "\n",
        "print('input-z -- 크기:',input_z.shape)\n",
        "print('input-real -- 크기:',input_real.shape)\n",
        "\n",
        "g_output = gen_model(input_z)\n",
        "print('생성자 출력 -- 크기:',g_output.shape)\n",
        "\n",
        "d_proba_real = disc_model(input_real)\n",
        "d_proba_fake = disc_model(g_output)\n",
        "print('판별자(진짜)--크기:',d_proba_real.shape)\n",
        "print('판별자(가짜)--크기:',d_proba_fake.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CdYeFoLzHME",
        "outputId": "31c2a670-b2a2-426e-b9db-533621df3efa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input-z -- 크기: torch.Size([32, 20])\n",
            "input-real -- 크기: torch.Size([32, 784])\n",
            "생성자 출력 -- 크기: torch.Size([32, 784])\n",
            "판별자(진짜)--크기: torch.Size([32, 1])\n",
            "판별자(가짜)--크기: torch.Size([32, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GAN 모델 훈련하기"
      ],
      "metadata": {
        "id": "Cla5QpP40nXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.BCELoss()\n",
        "# 생성자 손실\n",
        "g_labels_real = torch.ones_like(d_proba_fake)\n",
        "g_loss = loss_fn(d_proba_fake, g_labels_real)\n",
        "print(f'Generator Loss:{g_loss:.4f}')\n",
        "\n",
        "# 판별자 손실\n",
        "d_labels_real = torch.ones_like(d_proba_real)\n",
        "d_labels_fake = torch.zeros_like(d_proba_fake)\n",
        "\n",
        "d_loss_real = loss_fn(d_proba_real,d_labels_real)\n",
        "d_loss_fake = loss_fn(d_proba_fake, d_labels_fake)\n",
        "print(f\"판별자 손실:진짜{d_loss_real:.4f} 가짜{d_loss_fake:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etwdF-WS3i6g",
        "outputId": "8e21b4f8-3a77-4bf3-f903-658a1918e3b8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator Loss:0.6983\n",
            "판별자 손실:진짜0.7487 가짜0.6885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종훈련\n",
        "batch_size = 64\n",
        "torch.manual_seed(1)\n",
        "np.random.seed(1)\n",
        "\n",
        "#데이터셋 생성\n",
        "mnist_dl = DataLoader(mnist_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "#모델 생성\n",
        "gen_model = make_generator_network(\n",
        "    input_size=z_size,\n",
        "    num_hidden_layers=gen_hidden_layers,\n",
        "    num_hidden_units=gen_hidden_size,\n",
        "    num_output_units=np.prod(image_size)).to(device)\n",
        "\n",
        "disc_model = make_discriminator_network(\n",
        "    input_size=np.prod(image_size),\n",
        "    num_hidden_layers=disc_hidden_layers,\n",
        "    num_hidden_units=disc_hidden_size).to(device)\n",
        "# 손실함수와 옵티마이져\n",
        "loss_fn = nn.BCELoss()\n",
        "g_optimizer = torch.optim.Adam(gen_model.parameters())\n",
        "d_optimizer = torch.optim.Adam(disc_model.parameters())"
      ],
      "metadata": {
        "id": "4rfZOVIo4tJl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 판별자 훈련\n",
        "def d_train(x):\n",
        "  disc_model.zero_grad()\n",
        "  # 진짜 배치에서 판별자 훈련\n",
        "  batch_size = x.size(0)\n",
        "  x = x.view(batch_size, -1).to(device)\n",
        "  d_labels_real = torch.ones(batch_size, 1, device=device)\n",
        "\n",
        "  d_proba_real = disc_model(x)\n",
        "  d_loss_real = loss_fn(d_proba_real, d_labels_real)\n",
        "\n",
        "  # 가짜 배치에서 판별자 훈련\n",
        "  input_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
        "  g_output = gen_model(input_z)\n",
        "\n",
        "  d_proba_fake = disc_model(g_output)\n",
        "  d_labels_fake = torch.zeros(batch_size, 1, device=device)\n",
        "  d_loss_fake = loss_fn(d_proba_fake, d_labels_fake)\n",
        "\n",
        "  # 그레이디언트 역전파와 판별자 파라미터 최적화\n",
        "  d_loss = d_loss_real + d_loss_fake\n",
        "  d_loss.backward()\n",
        "  d_optimizer.step()\n",
        "\n",
        "  return d_loss.data.item(), d_proba_real.detach(), d_proba_fake.detach()"
      ],
      "metadata": {
        "id": "KU3BSEmm41YT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 생성자 훈련\n",
        "def g_train(x):\n",
        "  gen_model.zero_grad()\n",
        "\n",
        "  batch_size = x.size(0)\n",
        "  input_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
        "  g_labels_real = torch.ones(batch_size,1,device=device)\n",
        "\n",
        "  g_output = gen_model(input_z)\n",
        "  d_proba_fake = disc_model(g_output)\n",
        "  g_loss = loss_fn(d_proba_fake, g_labels_real)\n",
        "  # 그레이디언트 역전파와 생성자 파라미터 최적화\n",
        "  g_loss.backward()\n",
        "  g_optimizer.step()\n",
        "\n",
        "  return g_loss.data.item()"
      ],
      "metadata": {
        "id": "2joRvE3Y705b"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
        "\n",
        "def create_samples(g_model, input_z):\n",
        "    g_output = g_model(input_z)\n",
        "    images = torch.reshape(g_output, (batch_size, *image_size))\n",
        "    return (images+1)/2.0\n",
        "\n",
        "epoch_samples = []\n",
        "\n",
        "all_d_losses = []\n",
        "all_g_losses = []\n",
        "\n",
        "all_d_real = []\n",
        "all_d_fake = []\n",
        "\n",
        "num_epochs = 100\n",
        "torch.manual_seed(1)\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    d_losses, g_losses = [], []\n",
        "    d_vals_real, d_vals_fake = [], []\n",
        "    for i, (x, _) in enumerate(mnist_dl):\n",
        "        d_loss, d_proba_real, d_proba_fake = d_train(x)\n",
        "        d_losses.append(d_loss)\n",
        "        g_losses.append(g_train(x))\n",
        "\n",
        "        d_vals_real.append(d_proba_real.mean().cpu())\n",
        "        d_vals_fake.append(d_proba_fake.mean().cpu())\n",
        "\n",
        "    all_d_losses.append(torch.tensor(d_losses).mean())\n",
        "    all_g_losses.append(torch.tensor(g_losses).mean())\n",
        "    all_d_real.append(torch.tensor(d_vals_real).mean())\n",
        "    all_d_fake.append(torch.tensor(d_vals_fake).mean())\n",
        "    print(f'에포크 {epoch:03d} | 평균 손실 >>'\n",
        "          f' 생성자/판별자 {all_g_losses[-1]:.4f}/{all_d_losses[-1]:.4f}'\n",
        "          f' [판별자-진짜: {all_d_real[-1]:.4f} 판별자-가짜: {all_d_fake[-1]:.4f}]')\n",
        "    epoch_samples.append(\n",
        "        create_samples(gen_model, fixed_z).detach().cpu().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjUhCRkB8l5T",
        "outputId": "b4a37c23-5235-4498-a071-0e71b31b7a3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에포크 001 | 평균 손실 >> 생성자/판별자 0.8944/0.9068 [판별자-진짜: 0.8035 판별자-가짜: 0.4717]\n",
            "에포크 002 | 평균 손실 >> 생성자/판별자 0.9469/1.1271 [판별자-진짜: 0.6164 판별자-가짜: 0.4318]\n",
            "에포크 003 | 평균 손실 >> 생성자/판별자 0.9596/1.1998 [판별자-진짜: 0.5790 판별자-가짜: 0.4277]\n",
            "에포크 004 | 평균 손실 >> 생성자/판별자 0.9415/1.2163 [판별자-진짜: 0.5737 판별자-가짜: 0.4305]\n",
            "에포크 005 | 평균 손실 >> 생성자/판별자 0.9270/1.2284 [판별자-진짜: 0.5705 판별자-가짜: 0.4286]\n",
            "에포크 006 | 평균 손실 >> 생성자/판별자 0.9453/1.2473 [판별자-진짜: 0.5620 판별자-가짜: 0.4335]\n",
            "에포크 007 | 평균 손실 >> 생성자/판별자 1.0020/1.1734 [판별자-진짜: 0.5897 판별자-가짜: 0.4058]\n",
            "에포크 008 | 평균 손실 >> 생성자/판별자 1.0015/1.1883 [판별자-진짜: 0.5890 판별자-가짜: 0.4110]\n",
            "에포크 009 | 평균 손실 >> 생성자/판별자 0.9548/1.2096 [판별자-진짜: 0.5805 판별자-가짜: 0.4229]\n",
            "에포크 010 | 평균 손실 >> 생성자/판별자 0.9074/1.2498 [판별자-진짜: 0.5619 판별자-가짜: 0.4359]\n",
            "에포크 011 | 평균 손실 >> 생성자/판별자 0.9841/1.2001 [판별자-진짜: 0.5831 판별자-가짜: 0.4135]\n",
            "에포크 012 | 평균 손실 >> 생성자/판별자 0.9437/1.2165 [판별자-진짜: 0.5803 판별자-가짜: 0.4267]\n",
            "에포크 013 | 평균 손실 >> 생성자/판별자 0.9947/1.1981 [판별자-진짜: 0.5860 판별자-가짜: 0.4148]\n",
            "에포크 014 | 평균 손실 >> 생성자/판별자 0.9812/1.2052 [판별자-진짜: 0.5852 판별자-가짜: 0.4206]\n",
            "에포크 015 | 평균 손실 >> 생성자/판별자 0.9600/1.2153 [판별자-진짜: 0.5790 판별자-가짜: 0.4233]\n",
            "에포크 016 | 평균 손실 >> 생성자/판별자 0.8970/1.2414 [판별자-진짜: 0.5677 판별자-가짜: 0.4347]\n",
            "에포크 017 | 평균 손실 >> 생성자/판별자 0.8782/1.2710 [판별자-진짜: 0.5542 판별자-가짜: 0.4448]\n",
            "에포크 018 | 평균 손실 >> 생성자/판별자 0.8481/1.2878 [판별자-진짜: 0.5478 판별자-가짜: 0.4529]\n",
            "에포크 019 | 평균 손실 >> 생성자/판별자 0.8366/1.2874 [판별자-진짜: 0.5474 판별자-가짜: 0.4540]\n",
            "에포크 020 | 평균 손실 >> 생성자/판별자 0.8333/1.2935 [판별자-진짜: 0.5441 판별자-가짜: 0.4560]\n",
            "에포크 021 | 평균 손실 >> 생성자/판별자 0.8181/1.3075 [판별자-진짜: 0.5369 판별자-가짜: 0.4588]\n",
            "에포크 022 | 평균 손실 >> 생성자/판별자 0.7901/1.3261 [판별자-진짜: 0.5300 판별자-가짜: 0.4687]\n",
            "에포크 023 | 평균 손실 >> 생성자/판별자 0.8039/1.3242 [판별자-진짜: 0.5307 판별자-가짜: 0.4668]\n",
            "에포크 024 | 평균 손실 >> 생성자/판별자 0.7880/1.3316 [판별자-진짜: 0.5269 판별자-가짜: 0.4704]\n",
            "에포크 025 | 평균 손실 >> 생성자/판별자 0.7935/1.3272 [판별자-진짜: 0.5289 판별자-가짜: 0.4691]\n",
            "에포크 026 | 평균 손실 >> 생성자/판별자 0.7931/1.3283 [판별자-진짜: 0.5292 판별자-가짜: 0.4701]\n",
            "에포크 027 | 평균 손실 >> 생성자/판별자 0.8068/1.3142 [판별자-진짜: 0.5351 판별자-가짜: 0.4645]\n",
            "에포크 028 | 평균 손실 >> 생성자/판별자 0.7785/1.3344 [판별자-진짜: 0.5266 판별자-가짜: 0.4737]\n",
            "에포크 029 | 평균 손실 >> 생성자/판별자 0.8083/1.3146 [판별자-진짜: 0.5350 판별자-가짜: 0.4651]\n",
            "에포크 030 | 평균 손실 >> 생성자/판별자 0.8272/1.2943 [판별자-진짜: 0.5458 판별자-가짜: 0.4592]\n",
            "에포크 031 | 평균 손실 >> 생성자/판별자 0.8349/1.2993 [판별자-진짜: 0.5433 판별자-가짜: 0.4593]\n",
            "에포크 032 | 평균 손실 >> 생성자/판별자 0.8097/1.3111 [판별자-진짜: 0.5375 판별자-가짜: 0.4647]\n",
            "에포크 033 | 평균 손실 >> 생성자/판별자 0.7796/1.3282 [판별자-진짜: 0.5285 판별자-가짜: 0.4711]\n",
            "에포크 034 | 평균 손실 >> 생성자/판별자 0.7908/1.3272 [판별자-진짜: 0.5298 판별자-가짜: 0.4705]\n",
            "에포크 035 | 평균 손실 >> 생성자/판별자 0.7892/1.3293 [판별자-진짜: 0.5282 판별자-가짜: 0.4692]\n",
            "에포크 036 | 평균 손실 >> 생성자/판별자 0.7683/1.3390 [판별자-진짜: 0.5240 판별자-가짜: 0.4765]\n",
            "에포크 037 | 평균 손실 >> 생성자/판별자 0.7939/1.3240 [판별자-진짜: 0.5314 판별자-가짜: 0.4692]\n",
            "에포크 038 | 평균 손실 >> 생성자/판별자 0.7977/1.3156 [판별자-진짜: 0.5347 판별자-가짜: 0.4666]\n",
            "에포크 039 | 평균 손실 >> 생성자/판별자 0.7768/1.3358 [판별자-진짜: 0.5260 판별자-가짜: 0.4740]\n",
            "에포크 040 | 평균 손실 >> 생성자/판별자 0.7668/1.3419 [판별자-진짜: 0.5221 판별자-가짜: 0.4767]\n",
            "에포크 041 | 평균 손실 >> 생성자/판별자 0.7782/1.3348 [판별자-진짜: 0.5270 판별자-가짜: 0.4733]\n",
            "에포크 042 | 평균 손실 >> 생성자/판별자 0.7911/1.3277 [판별자-진짜: 0.5295 판별자-가짜: 0.4699]\n",
            "에포크 043 | 평균 손실 >> 생성자/판별자 0.8046/1.3195 [판별자-진짜: 0.5340 판별자-가짜: 0.4669]\n",
            "에포크 044 | 평균 손실 >> 생성자/판별자 0.7896/1.3253 [판별자-진짜: 0.5300 판별자-가짜: 0.4702]\n",
            "에포크 045 | 평균 손실 >> 생성자/판별자 0.8001/1.3171 [판별자-진짜: 0.5338 판별자-가짜: 0.4664]\n",
            "에포크 046 | 평균 손실 >> 생성자/판별자 0.8264/1.3015 [판별자-진짜: 0.5424 판별자-가짜: 0.4603]\n",
            "에포크 047 | 평균 손실 >> 생성자/판별자 0.8166/1.3105 [판별자-진짜: 0.5370 판별자-가짜: 0.4632]\n",
            "에포크 048 | 평균 손실 >> 생성자/판별자 0.8237/1.3064 [판별자-진짜: 0.5387 판별자-가짜: 0.4608]\n",
            "에포크 049 | 평균 손실 >> 생성자/판별자 0.7723/1.3331 [판별자-진짜: 0.5264 판별자-가짜: 0.4738]\n",
            "에포크 050 | 평균 손실 >> 생성자/판별자 0.7732/1.3403 [판별자-진짜: 0.5234 판별자-가짜: 0.4752]\n",
            "에포크 051 | 평균 손실 >> 생성자/판별자 0.7602/1.3464 [판별자-진짜: 0.5195 판별자-가짜: 0.4777]\n",
            "에포크 052 | 평균 손실 >> 생성자/판별자 0.7693/1.3406 [판별자-진짜: 0.5234 판별자-가짜: 0.4766]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 시각화를 위해서 수집한 변수를 저장하고 불러오기\n",
        "saved_variables = {\n",
        "    'epoch_samples': epoch_samples,\n",
        "    'all_d_losses': all_d_losses,\n",
        "    'all_g_losses': all_g_losses,\n",
        "    'all_d_real': all_d_real,\n",
        "    'all_d_fake': all_d_fake\n",
        "}\n",
        "torch.save(saved_variables,'/content/drive/MyDrive/saved_variables,pth')\n",
        "# 불러오기\n",
        "loaded_variables = torch.load('/content/drive/MyDrive/saved_variables,pth')\n",
        "# 각 변수를 불러오기\n",
        "loaded_epoch_samples = loaded_variables['epoch_samples']\n",
        "loaded_all_d_losses = loaded_variables['all_d_losses']\n",
        "loaded_all_g_losses = loaded_variables['all_g_losses']\n",
        "loaded_all_d_real = loaded_variables['all_d_real']\n",
        "loaded_all_d_fake = loaded_variables['all_d_fake']\n",
        "\n",
        "\n",
        "# 판별자 모델\n",
        "torch.save(disc_model,'/content/drive/MyDrive/disc_model.pth')\n",
        " # 생성자 모델\n",
        "torch.save(gen_model,'/content/drive/MyDrive/gen_model.pth')\n",
        "\n",
        "loaded_disc_model = torch.load('/content/drive/MyDrive/disc_model.pth')\n",
        "loaded_gen_model = torch.load('/content/drive/MyDrive/gen_model.pth')"
      ],
      "metadata": {
        "id": "007XAiK1-Owa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6mdLPeEe-PDy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vBNgIjeDwqbT"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "합성곱 신경망의 구성 요소"
      ],
      "metadata": {
        "id": "pBdCg_JGwwix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url='https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch14/figures/14_01.png', width=700)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "sS5k-7KWw0Cg",
        "outputId": "df14567b-a9e7-4a47-facf-3a6ade4cc655"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch14/figures/14_01.png\" width=\"700\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url='https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch14/figures/14_02.png', width=700)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "AB3g4QDqxD-W",
        "outputId": "70b2c813-d705-4e03-f0f2-9c22ffca88bf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch14/figures/14_02.png\" width=\"700\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "합성곱 출력 크기 계산"
      ],
      "metadata": {
        "id": "0LVJar1UxRSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "nlXoy9qBxLop"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv1d(x, w, p=0, s=1):\n",
        "  w_rot = np.array(w[::-1])\n",
        "  x_padded = np.array(x)\n",
        "  if p > 0:\n",
        "    zero_pad = np.zeros(shape=p)\n",
        "    x_padded = np.concatenate(\n",
        "        [zero_pad, x_padded, zero_pad]\n",
        "    )\n",
        "    res = []\n",
        "    for i in range(0, int( (len(x_padded) - len(w_rot))) + 1, s):\n",
        "      res.append(np.sum(\n",
        "          x_padded[i: i+w_rot.shape[0]] * w_rot\n",
        "      ))\n",
        "    return np.array(res)\n",
        "\n",
        "x = [1,3,2,4,5,6,1,3]\n",
        "w = [1,0,3,1,2]\n",
        "print(f\"Conv1d : {conv1d(x,w,p=2,s=1) }\")\n",
        "print(f\"numpy : {np.convolve(x,w,mode='same') }\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_1aT2llxVMr",
        "outputId": "89a3f9de-234f-4811-ba72-db5b76cc1861"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv1d : [ 5. 14. 16. 26. 24. 34. 19. 22.]\n",
            "numpy : [ 5 14 16 26 24 34 19 22]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2D conv"
      ],
      "metadata": {
        "id": "DhAzxJ9VzMcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url='https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch14/figures/14_05.png', width=700)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "QrexOKLGy65D",
        "outputId": "45a49d3d-7673-4f49-b441-1d0babc1f9e4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch14/figures/14_05.png\" width=\"700\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url='https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch14/figures/14_06.png', width=600)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "Qk-358CgzP_E",
        "outputId": "16e535a2-4bf3-4a6e-dae6-feaf69db22a7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch14/figures/14_06.png\" width=\"600\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url='https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch14/figures/14_07.png', width=800)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "TWJanddAzTNa",
        "outputId": "3ce51a53-920a-4025-b175-b4e7066e0fd4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch14/figures/14_07.png\" width=\"800\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.signal\n",
        "\n",
        "def conv2D(x, w, p=(0,0), s=(1,1)):\n",
        "  w_rot = np.array(w)[::-1, ::-1]\n",
        "  X_orig = np.array(x)\n",
        "  n1 = X_orig.shape[0] + 2*p[0]\n",
        "  n2 = X_orig.shape[1] + 2*p[1]\n",
        "  x_padded = np.zeros(shape=(n1,n2))\n",
        "  x_padded[ p[0]:p[0]+X_orig.shape[0],\n",
        "           p[1]:p[1]+X_orig.shape[1]\n",
        "           ] = X_orig\n",
        "\n",
        "  res = []\n",
        "  for i in range(0, int( (x_padded.shape[0] - w_rot.shape[0])/s[0])+1, s[0]):\n",
        "    res.append([])\n",
        "    for j in range(0, int( (x_padded.shape[1] - w_rot.shape[1])/s[1])+1, s[1]):\n",
        "      X_sub = x_padded[i:i+w_rot.shape[0], j:j+w_rot.shape[1]]\n",
        "      res[-1].append(np.sum(X_sub * w_rot))\n",
        "  return(np.array(res))\n",
        "\n",
        "X = [[1, 3, 2, 4], [5, 6, 1, 3], [1, 2, 0, 2], [3, 4, 3, 2]]\n",
        "W = [[1, 0, 3], [1, 2, 1], [0, 1, 1]]\n",
        "\n",
        "print(f'conv2d : {conv2D(X,W,p=(1,1), s=(1,1))}')\n",
        "print(f\"사이파이 : { scipy.signal.convolve2d(X, W, mode='same') }\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh8XC6BBzWCM",
        "outputId": "44f5f58b-f7d3-4390-8173-e310fecfd100"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv2d : [[11. 25. 32. 13.]\n",
            " [19. 25. 24. 13.]\n",
            " [13. 28. 25. 17.]\n",
            " [11. 17. 14.  9.]]\n",
            "사이파이 : [[11 25 32 13]\n",
            " [19 25 24 13]\n",
            " [13 28 25 17]\n",
            " [11 17 14  9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url='https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch14/figures/14_08.png', width=700)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "0sm9qJq23FWP",
        "outputId": "9cab2379-a0aa-44d1-b2bb-1148cbe7ccd0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch14/figures/14_08.png\" width=\"700\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url='https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch14/figures/14_09.png', width=800)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "Ue0CpaVs5nZ1",
        "outputId": "25ad97a5-dcb1-4ab3-994c-23a5c27a8340"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch14/figures/14_09.png\" width=\"800\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "L2규제 드롭아웃으로  신경망 규제"
      ],
      "metadata": {
        "id": "Hh1I4oQz6JIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url='https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch14/figures/14_10.png', width=700)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "zGCa-sxx5t_y",
        "outputId": "d83a3fa6-218e-413d-9ec7-5d9e7a4842cf"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch14/figures/14_10.png\" width=\"700\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "loss_func = nn.BCELoss()\n",
        "loss = loss_func(torch.tensor([0.9]), torch.tensor([1.0])  )\n",
        "l2_lambda = 0.001\n",
        "\n",
        "conv_layer = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=5)\n",
        "l2_penalty = l2_lambda * sum( [  (p**2).sum() for p in conv_layer.parameters()  ])\n",
        "loss_with_penalty = loss + l2_penalty\n",
        "\n",
        "linear_layer = nn.Linear(10,16)\n",
        "l2_penalty = l2_lambda * sum( [  (p**2).sum() for p in linear_layer.parameters()  ])\n",
        "loss_with_penalty = loss + l2_penalty"
      ],
      "metadata": {
        "id": "i-eilFJb6MYc"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "분류를 위한 손실함수"
      ],
      "metadata": {
        "id": "lAwg6Iik9odB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# logit : 확률을 변환하는데 사용하는 함수  - 로지스틱회귀 와 같은 분류모델에서 사용\n",
        "# 입력특성과 해당 클래스 사이의 관계를 모델링"
      ],
      "metadata": {
        "id": "VPTFmcG17RzG"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "SI1QGea0-FNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# p 0과 1사이의 확률\n",
        "# pfmf 0 < p < 1 범위에서 임의의 실수로 변환\n",
        "# 로짓은 확률의 로그오즈(log odds)를 나타내며 로그오즈는 성공확률과 실패확률 사이의 비율에 대한 자연로그\n",
        "# 로짓은 분류문제에서 사용\n",
        "# 로짓값을 확률로 변환하기 위해서는 로지스틱 함수가 적용"
      ],
      "metadata": {
        "id": "gUA4RaFu-Em9"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### 이진 크로스 엔트로피\n",
        "logit = torch.tensor([0.8])\n",
        "probas = torch.sigmoid(logit)\n",
        "target = torch.tensor([1.0])\n",
        "\n",
        "bce_loss_fn = nn.BCELoss()\n",
        "bce_logits_loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "print(f\"BCE(확률) : {bce_loss_fn(probas, target):.4f}\")\n",
        "print(f\"BCE(로짓) : {bce_logits_loss_fn(logit, target):.4f}\")\n",
        "\n",
        "##### 범주형 크로스 엔트로피\n",
        "logit = torch.tensor([[1.5,0.8,2.1]])\n",
        "probas = torch.softmax(logit, dim=1)\n",
        "target = torch.tensor([2])\n",
        "\n",
        "cce_loss_fn = nn.NLLLoss()  # 범주형 크로스 엔트로피 손실함수\n",
        "cce_logits_loss_fn = nn.CrossEntropyLoss() # 로짓값을 입력으로 받는 범주형 크로스 엔트로피 손실함수\n",
        "\n",
        "print(f\"BCE(확률) : {cce_logits_loss_fn(logit, target):.4f}\")\n",
        "print(f\"BCE(로짓) : {cce_loss_fn(torch.log(probas), target):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAcXFYYI-zAI",
        "outputId": "490a4dc1-cd5c-46e8-b0f1-0bdf1c86b73e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BCE(확률) : 0.3711\n",
            "BCE(로짓) : 0.3711\n",
            "BCE(확률) : 0.5996\n",
            "BCE(로짓) : 0.5996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "파이토치를 사용하여 심층 합성곱 신경망 구현\n",
        "  - 다층 CNN 구조"
      ],
      "metadata": {
        "id": "LMMAFPh9Bfuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Image(url='https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch14/figures/14_12.png', width=800)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "hpTkn9jF_ni7",
        "outputId": "2000cb47-bb87-449c-d680-b4e11675a985"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch14/figures/14_12.png\" width=\"800\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "image_path = './'\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "mnist_dataset = torchvision.datasets.MNIST(root=image_path,train=True,transform=transform,download=True)\n",
        "from torch.utils.data import Subset\n",
        "mnist_valid_dataset = Subset(mnist_dataset, torch.arange(10000))\n",
        "mnist_train_dataset = Subset(mnist_dataset, torch.arange(10000,len(mnist_dataset)))\n",
        "mnist_test_dataset = torchvision.datasets.MNIST(root=image_path,train=False,transform=transform,download=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGDbNJkrBsc_",
        "outputId": "80d48962-fa77-4d5c-cb51-60ba56d84f8e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 110381999.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 26734869.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 34376122.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 11490065.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 64\n",
        "torch.manual_seed(1)\n",
        "train_dl = DataLoader(mnist_train_dataset, batch_size, shuffle=True)\n",
        "void_dl = DataLoader(mnist_valid_dataset, batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "u4hZ6cGMCEXw"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.nn 모듈을 사용해서 CNN 구현"
      ],
      "metadata": {
        "id": "Rd7tuDX6EPxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential()\n",
        "model.add_module('conv1', nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding=2) )\n",
        "model.add_module('relu1', nn.ReLU())\n",
        "model.add_module('pool1', nn.MaxPool2d(kernel_size=2))\n",
        "\n",
        "model.add_module('conv2', nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2) )\n",
        "model.add_module('relu2', nn.ReLU())\n",
        "model.add_module('pool2', nn.MaxPool2d(kernel_size=2))\n",
        "\n",
        "x = torch.ones((4,1,28,28))\n",
        "model(x).shape\n",
        "\n",
        "# model = nn.Sequential()\n",
        "# model.add_module('conv1', nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding=2))\n",
        "# model.add_module('relu1', nn.ReLU())\n",
        "# model.add_module('pool1', nn.MaxPool2d(kernel_size=2))\n",
        "# model.add_module('conv2', nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2))\n",
        "# model.add_module('relu2', nn.ReLU())\n",
        "# model.add_module('pool2', nn.MaxPool2d(kernel_size=2))\n",
        "\n",
        "# x = torch.ones((4, 1, 28, 28))\n",
        "# model(x).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_crpAK0EMpN",
        "outputId": "2454835f-b8f3-4d8e-ae2f-4f23b1ace7e3"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 64, 7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.add_module('flatten', nn.Flatten())\n",
        "x = torch.ones((4, 1, 28, 28))\n",
        "model(x).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sw25YLfkFI3n",
        "outputId": "3042f499-f676-42de-dd42-57bfba1bb19a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 3136])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.add_module('fc1', nn.Linear(3136, 1024))\n",
        "model.add_module('relu3', nn.ReLU())\n",
        "model.add_module('dropout', nn.Dropout(p=0.5))\n",
        "model.add_module('fc2', nn.Linear(1024, 10))"
      ],
      "metadata": {
        "id": "pymxTbUKGu4w"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "6ImCJTdDHGmk"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yk2AOXUkHThV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
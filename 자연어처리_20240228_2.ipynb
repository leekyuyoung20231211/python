{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtOt-maGjUbz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "json 처리하기"
      ],
      "metadata": {
        "id": "BNYDnTmRjWP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "lkajew1GjYNK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/sarcasm.json') as f:\n",
        "  datastore = json.load(f)\n",
        "  # for item in data:\n",
        "  #   print(item['article_link'],item['headline'],item['is_sarcastic'])"
      ],
      "metadata": {
        "id": "DkzfWzPKjg2M"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 전처리"
      ],
      "metadata": {
        "id": "He3zCG64kYtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from bs4 import BeautifulSoup\n",
        "import string\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "g8D4F8msj1fn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\",\n",
        "             \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\",\n",
        "             \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\",\n",
        "             \"he\", \"hed\", \"hes\", \"her\", \"here\", \"heres\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\",\n",
        "             \"hows\", \"i\", \"id\", \"ill\", \"im\", \"ive\", \"if\", \"in\", \"into\", \"is\", \"it\", \"its\", \"itself\",\n",
        "             \"lets\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\",\n",
        "             \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"shed\", \"shell\", \"shes\", \"should\",\n",
        "             \"so\", \"some\", \"such\", \"than\", \"that\", \"thats\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\",\n",
        "             \"there\", \"theres\", \"these\", \"they\", \"theyd\", \"theyll\", \"theyre\", \"theyve\", \"this\", \"those\", \"through\",\n",
        "             \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"wed\", \"well\", \"were\", \"weve\", \"were\",\n",
        "             \"what\", \"whats\", \"when\", \"whens\", \"where\", \"wheres\", \"which\", \"while\", \"who\", \"whos\", \"whom\", \"why\",\n",
        "             \"whys\", \"with\", \"would\", \"you\", \"youd\", \"youll\", \"youre\", \"youve\", \"your\", \"yours\", \"yourself\",\n",
        "             \"yourselves\"]\n",
        "table = str.maketrans('','', string.punctuation)  # string.punctuation 포함된 문자를 제거"
      ],
      "metadata": {
        "id": "WeIpt0slkj6w"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "labels = []\n",
        "urls = []\n",
        "for item in datastore:\n",
        "  sentence = item['headline'].lower()\n",
        "  sentence = sentence.replace(',',' , ')\n",
        "  sentence = sentence.replace('.',' . ')\n",
        "  sentence = sentence.replace('-',' - ')\n",
        "  sentence = sentence.replace('/',' / ')\n",
        "  soup = BeautifulSoup(sentence)\n",
        "  sentence = soup.get_text()\n",
        "  words = sentence.split()\n",
        "  filtered_sentence = \"\"\n",
        "  for word in words:\n",
        "    word = word.translate(table)\n",
        "    if word not in stopwords:\n",
        "      filtered_sentence = filtered_sentence + word + \" \"\n",
        "  sentences.append(filtered_sentence)\n",
        "  labels.append(item['is_sarcastic'])\n",
        "  urls.append(item['article_link'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYOwlowNksaW",
        "outputId": "ef004743-6d6f-44f9-a0e5-46a260f1f7f1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-1d4046a7bb73>:10: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  soup = BeautifulSoup(sentence)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000\n",
        "embedding_dim = 16\n",
        "max_length = 100\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "training_size = 23000"
      ],
      "metadata": {
        "id": "mX40Z-z9k0Sv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_sentences = sentences[0:training_size]\n",
        "testing_sentences = sentences[training_size:]\n",
        "training_labels = labels[0:training_size]\n",
        "testing_labels = labels[training_size:]"
      ],
      "metadata": {
        "id": "8jyPproult5w"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ],
      "metadata": {
        "id": "CK_NZU-CmEdA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "텐서플로 임베딩"
      ],
      "metadata": {
        "id": "byYizHQmmRJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "training_padding = np.array(training_padded)\n",
        "training_labels = np.array(training_labels)\n",
        "testing_padding = np.array(testing_padded)\n",
        "testing_labels = np.array(testing_labels)"
      ],
      "metadata": {
        "id": "-DE_iPfumOM0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        " tf.keras.layers.Embedding(vocab_size,embedding_dim),\n",
        " tf.keras.layers.GlobalAveragePooling1D(),  # 시퀀스의 길이에 상관없이 각 시퀀스의 평균 임베딩 계산\n",
        " tf.keras.layers.Dense(24, activation='relu'),\n",
        " tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss = 'binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "xywxNs0am6Ac"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kt_MvPfQnvUC",
        "outputId": "37706fc7-b03f-48a1-b280-1fd528fce4e5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, None, 16)          160000    \n",
            "                                                                 \n",
            " global_average_pooling1d_1  (None, 16)                0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 24)                408       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 160433 (626.69 KB)\n",
            "Trainable params: 160433 (626.69 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "history = model.fit(training_padding,training_labels,epochs=num_epochs,\n",
        "                    validation_data = (testing_padding,testing_labels))"
      ],
      "metadata": {
        "id": "kWCj5jsznybJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1 . 이미지분류 모델을 생성\n",
        "\n",
        "2 . 모델을 이용해서 폴더에 있는 영상을 각 폴더로 분류하는 기능"
      ],
      "metadata": {
        "id": "UxrGuAhkJ5_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 이미지 분류모델을 생성"
      ],
      "metadata": {
        "id": "2_rwlawTKLK3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# c c p d c c p d flatten fd d fc\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten,Dense, Conv2D,MaxPool2D,Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import os"
      ],
      "metadata": {
        "id": "GTFXT6mXKOsM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train,y_train),(X_test,y_test)= tf.keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6El0rdQNEDf",
        "outputId": "c7dc1838-b276-467b-d808-91bd26936fd8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 13s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled = X_train / 255. ; X_test_scaled = X_test / 255."
      ],
      "metadata": {
        "id": "b6yFng4jNEGj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "  Conv2D(64,3,activation='relu',input_shape=(32,32,3)),\n",
        "  Conv2D(128,3,activation='relu'),\n",
        "  MaxPool2D(),\n",
        "  Dropout(0.4),\n",
        "  Conv2D(128,3,activation='relu'),\n",
        "  Conv2D(128,3,activation='relu'),\n",
        "  MaxPool2D(),\n",
        "  Dropout(0.4),\n",
        "  Flatten(),\n",
        "  Dense(100,activation='relu'),\n",
        "  Dropout(0.4),\n",
        "  Dense(10,activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "Ho-H3kNQKd2G"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqANsVgWMMzt",
        "outputId": "c0c54b51-a747-47d3-ee96-6f0384b2f4ca"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 64)        1792      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 14, 14, 128)       0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 128)       147584    \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 10, 10, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 5, 5, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 3200)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               320100    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 691926 (2.64 MB)\n",
            "Trainable params: 691926 (2.64 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',metrics=['acc'],loss='sparse_categorical_crossentropy')\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint('best_cnn.keras',save_best_only=True)\n",
        "ealy_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=3,restore_best_weights=True)\n",
        "hist = model.fit(X_train_scaled,y_train,validation_data=(X_test_scaled,y_test),callbacks=[ealy_stopping_cb,checkpoint_cb], epochs=20)"
      ],
      "metadata": {
        "id": "8iaI-7kFMRr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile"
      ],
      "metadata": {
        "id": "l9alT3-BO4Hj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with ZipFile('/content/test_images.zip','r') as f:\n",
        "  f.extractall(\"./\")"
      ],
      "metadata": {
        "id": "VfmNTWV0RmXX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_name = ['airplane','automobile','bird','cat','deer','dog','flog','horse','ship','truck']"
      ],
      "metadata": {
        "id": "YSzxFOHaSIZh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_path = '/content/'\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "UkzDipPvShUu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = []; original_files = []\n",
        "for filepath in glob(\"./*.jpg\"):\n",
        "  original_files.append(filepath)\n",
        "  img = Image.open(filepath)\n",
        "  x = np.array(img.resize([32,32])) / 255.\n",
        "  x_test.append(x)\n",
        "x_test = np.array(x_test)"
      ],
      "metadata": {
        "id": "GVeNJymjTAJi"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgPfChFdTDih",
        "outputId": "99fb1d28-7034-44c0-f10a-dce475499468"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil"
      ],
      "metadata": {
        "id": "8SSLOgzqXQWg"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = 'img_category'\n",
        "if not os.path.exists(output_dir):\n",
        "  os.makedirs(output_dir)\n",
        "\n",
        "pred = model.predict(x_test)\n",
        "\n",
        "# 예측한 데이터를 순회\n",
        "for idx,preddata in enumerate(pred):\n",
        "  index = np.argmax(preddata) # 10개의 클래스에 대한 확률 가장큰 확률의 인덱스\n",
        "  classname = class_name[index]  # 가장큰 인덱스에 해당하는 클래스명\n",
        "  target_dif_file = output_dir+'/'+ classname\n",
        "  if not os.path.exists( target_dif_file): # 클래스명으로 디렉터리 생성\n",
        "    os.makedirs(target_dif_file)\n",
        "  shutil.copy(original_files[idx] ,target_dif_file )  # 해당 디렉터리로 데이터를 이동\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tqj8WMVCX8-n",
        "outputId": "4673bfc3-2418-4042-f4d7-7ddc697189b3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RsNet50모델을 학습없이 사용해 보기"
      ],
      "metadata": {
        "id": "h5J4IOXua7uN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input\n",
        "base_model = ResNet50(include_top=False,input_shape=(32, 32,3))\n",
        "# base_model.trainable = False # 가중치 고정\n",
        "cnn =Sequential()\n",
        "cnn.add(base_model)\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(1024,activation='relu'))\n",
        "cnn.add(Dropout(0.25))\n",
        "cnn.add(Dense(10,activation='softmax'))"
      ],
      "metadata": {
        "id": "LyVARjxnaSmw"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "adam = Adam(learning_rate=0.0001)  # 가중치를 새로운데이터로 학습하면서 설정한 값을 사용-> 미세조정\n",
        "cnn.compile(optimizer=adam,metrics=['acc'],loss='sparse_categorical_crossentropy')\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint('best_ReNet50.keras',save_best_only=True)\n",
        "ealy_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=3,restore_best_weights=True)\n",
        "hist = cnn.fit(X_train_scaled,y_train,validation_data=(X_test_scaled,y_test),callbacks=[ealy_stopping_cb,checkpoint_cb], epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ6Pn-uma_Su",
        "outputId": "f7b8790b-9f95-4d07-b29e-3ff6f4a286f5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 129s 50ms/step - loss: 1.2625 - acc: 0.5784 - val_loss: 0.7761 - val_acc: 0.7375\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 78s 50ms/step - loss: 0.7376 - acc: 0.7508 - val_loss: 0.6633 - val_acc: 0.7789\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 74s 47ms/step - loss: 0.5536 - acc: 0.8125 - val_loss: 0.6727 - val_acc: 0.7787\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 80s 51ms/step - loss: 0.4400 - acc: 0.8504 - val_loss: 0.6128 - val_acc: 0.8030\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 72s 46ms/step - loss: 0.3414 - acc: 0.8841 - val_loss: 0.6222 - val_acc: 0.8085\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 74s 48ms/step - loss: 0.2720 - acc: 0.9074 - val_loss: 0.7711 - val_acc: 0.7873\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 72s 46ms/step - loss: 0.2095 - acc: 0.9301 - val_loss: 0.6597 - val_acc: 0.8168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "x_test = []; original_files = []\n",
        "for filepath in glob(\"./*.jpg\"):\n",
        "  original_files.append(filepath)\n",
        "  img = Image.open(filepath)\n",
        "  x = np.array(img.resize([32,32])) / 255.\n",
        "  x_test.append(x)\n",
        "x_test = np.array(x_test)\n",
        "\n",
        "\n",
        "output_dir = 'img_category4'\n",
        "if not os.path.exists(output_dir):\n",
        "  os.makedirs(output_dir)\n",
        "\n",
        "pred = cnn.predict(x_test)\n",
        "\n",
        "# 예측한 데이터를 순회\n",
        "for idx,preddata in enumerate(pred):\n",
        "  index = np.argmax(preddata) # 10개의 클래스에 대한 확률 가장큰 확률의 인덱스\n",
        "  classname = class_name[index]  # 가장큰 인덱스에 해당하는 클래스명\n",
        "  target_dif_file = output_dir+'/'+ classname\n",
        "  if not os.path.exists( target_dif_file): # 클래스명으로 디렉터리 생성\n",
        "    os.makedirs(target_dif_file)\n",
        "  shutil.copy(original_files[idx] ,target_dif_file )  # 해당 디렉터리로 데이터를 이동"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNoDHImjcjs2",
        "outputId": "1ccb7e2f-5f28-4dad-ef3d-6cdb9956c954"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 853ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "80WybG_fdLAZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
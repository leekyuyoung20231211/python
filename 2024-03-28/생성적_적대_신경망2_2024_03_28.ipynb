{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pquNMcnfrHxl"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "합성곱 GAN 과 바서슈타인 GAN 으로 합성 이미지 품질 높이기"
      ],
      "metadata": {
        "id": "dCaQrcxMtkIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url='https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch17/figures/17_09.png', width=700)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "L6kW-tKrtisI",
        "outputId": "54e03f8f-668d-49dd-b847-1bdc9ec40d88"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch17/figures/17_09.png\" width=\"700\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "배치정규화"
      ],
      "metadata": {
        "id": "0TA89mv-tiuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url='https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch17/figures/17_11.png', width=700)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "MZC8QWD6tiw3",
        "outputId": "e45f3a0f-3b02-440c-c49e-178567d73585"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch17/figures/17_11.png\" width=\"700\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "생성자와 판별자"
      ],
      "metadata": {
        "id": "rtB9iqNWtizO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url='https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch17/figures/17_12.png', width=700)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "qFy8TPhfti1d",
        "outputId": "0e0d0644-351f-4df6-b362-52d4d30a08e8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch17/figures/17_12.png\" width=\"700\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url='https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch17/figures/17_13.png', width=700)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "kaDf26KFti30",
        "outputId": "e683e010-ba60-45fb-d8ce-7d76f8eb0d10"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch17/figures/17_13.png\" width=\"700\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "POKq8NBfti6L",
        "outputId": "6601a44d-810c-42c0-cfed-9daaf00079c7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "-IzcpxVgti8V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "x3C3agu2ti-Z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "image_path = './'\n",
        "transfom = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5), std=(0.5))\n",
        "])\n",
        "\n",
        "mnist_dataset = torchvision.datasets.MNIST(root=image_path, train=True, transform=transfom,download=True)\n",
        "\n",
        "batch_size = 64\n",
        "torch.manual_seed(1)\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "mnist_dl = DataLoader(mnist_dataset, batch_size=batch_size,shuffle=True,drop_last=True)"
      ],
      "metadata": {
        "id": "RpYfFiXvtjC4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_generator_network(input_size, n_filters):\n",
        "  model = nn.Sequential(\n",
        "      nn.ConvTranspose2d(input_size, n_filters*4, 4,1,0,bias=False),\n",
        "      nn.BatchNorm2d(n_filters*4),\n",
        "      nn.LeakyReLU(0.2),\n",
        "\n",
        "      nn.ConvTranspose2d(n_filters*4, n_filters*2,3,2,1,bias=False),\n",
        "      nn.BatchNorm2d(n_filters*2),\n",
        "      nn.LeakyReLU(0.2),\n",
        "\n",
        "      nn.ConvTranspose2d(n_filters*2, n_filters,4,2,1,bias=False),\n",
        "      nn.BatchNorm2d(n_filters),\n",
        "      nn.LeakyReLU(0.2),\n",
        "\n",
        "      nn.ConvTranspose2d(n_filters, 1,4,2,1, bias=False),\n",
        "      nn.Tanh()\n",
        "  )\n",
        "  return model\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self,n_filters):\n",
        "    super().__init__()\n",
        "    self.network = nn.Sequential(\n",
        "        nn.Conv2d(1,n_filters, 4,2,1,bias=False),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(n_filters, n_filters*2,4,2,1, bias=False),\n",
        "        nn.BatchNorm2d(n_filters*2),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(n_filters*2, n_filters*4,3,2,1, bias=False),\n",
        "        nn.BatchNorm2d(n_filters*4),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(n_filters*4,1,4,1,0,bias=False),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self, input):\n",
        "    output = self.network(input)\n",
        "    return output.view(-1,1).squeeze(0)"
      ],
      "metadata": {
        "id": "H0OLBQw8wNtv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z_size = 100\n",
        "image_size = (28,28)\n",
        "n_filters = 32\n",
        "gen_model = make_generator_network(z_size, n_filters).to(device)\n",
        "print(gen_model)\n",
        "disc_model = Discriminator(n_filters).to(device)\n",
        "print(disc_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdCR_eLb10b6",
        "outputId": "13414499-b231-4378-8d6d-2fff20c3db0a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): ConvTranspose2d(100, 128, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): LeakyReLU(negative_slope=0.2)\n",
            "  (3): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): LeakyReLU(negative_slope=0.2)\n",
            "  (6): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (8): LeakyReLU(negative_slope=0.2)\n",
            "  (9): ConvTranspose2d(32, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (10): Tanh()\n",
            ")\n",
            "Discriminator(\n",
            "  (network): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2)\n",
            "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2)\n",
            "    (8): Conv2d(128, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (9): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실함수와 옵티마이져\n",
        "loss_fn = nn.BCELoss()\n",
        "g_optimizer = torch.optim.Adam(gen_model.parameters(),0.0003)\n",
        "d_optimizer = torch.optim.Adam(disc_model.parameters(), 0.0002)"
      ],
      "metadata": {
        "id": "2WgeVZSy2Kva"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_noise(batch_size, z_size,mode_z):\n",
        "  if mode_z == 'uniform':\n",
        "    input_z = torch.rand(batch_size, z_size,1,1)*2 - 1\n",
        "  elif mode_z == 'normal':\n",
        "    input_z = torch.randn(batch_size, z_size,1,1)\n",
        "  return input_z"
      ],
      "metadata": {
        "id": "JhLMGCTE2taW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 판별자 훈련\n",
        "def d_train(x):\n",
        "  disc_model.zero_grad()\n",
        "    # 진짜 배치에서 판별자 훈련\n",
        "  batch_size = x.size(0)\n",
        "  x = x.to(device)\n",
        "  d_labels_real = torch.ones(batch_size, 1, device=device)\n",
        "\n",
        "  d_proba_real = disc_model(x)\n",
        "  d_loss_real = loss_fn(d_proba_real, d_labels_real)\n",
        "\n",
        "  # 가짜 배치에서 판별자 훈련\n",
        "  input_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
        "  g_output = gen_model(input_z)\n",
        "\n",
        "  d_proba_fake = disc_model(g_output)\n",
        "  d_labels_fake = torch.zeros(batch_size, 1, device=device)\n",
        "  d_loss_fake = loss_fn(d_proba_fake, d_labels_fake)\n",
        "\n",
        "  # 그레이디언트 역전파와 판별자 파라미터 최적화\n",
        "  d_loss = d_loss_real + d_loss_fake\n",
        "  d_loss.backward()\n",
        "  d_optimizer.step()\n",
        "\n",
        "  return d_loss.data.item(), d_proba_real.detach(), d_proba_fake.detach()"
      ],
      "metadata": {
        "id": "J5p8oiqK3Ggo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 생성자 훈련\n",
        "def g_train(x):\n",
        "  gen_model.zero_grad()\n",
        "  batch_size = x.size(0)\n",
        "  input_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
        "  g_labels_real = torch.ones((batch_size,1),device=device)\n",
        "\n",
        "  g_output = gen_model(input_z)\n",
        "  d_proba_fake = disc_model(g_output)\n",
        "  g_loss = loss_fn(d_proba_fake, g_labels_real)\n",
        "\n",
        "  # 그레이디언트 역전파와 생성자 파라미터 최적화\n",
        "  g_loss.backward()\n",
        "  g_optimizer.step()\n",
        "\n",
        "  return g_loss.data.item()"
      ],
      "metadata": {
        "id": "PnE_gwTu44lv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mode_z = 'uniform'\n",
        "fixed_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
        "\n",
        "def create_samples(g_model, input_z):\n",
        "    g_output = g_model(input_z)\n",
        "    images = torch.reshape(g_output, (batch_size, *image_size))\n",
        "    return (images+1)/2.0\n",
        "\n",
        "epoch_samples = []\n",
        "\n",
        "num_epochs = 100\n",
        "torch.manual_seed(1)\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    gen_model.train()\n",
        "    d_losses, g_losses = [], []\n",
        "    for i, (x, _) in enumerate(mnist_dl):\n",
        "        d_loss, d_proba_real, d_proba_fake = d_train(x)\n",
        "        d_losses.append(d_loss)\n",
        "        g_losses.append(g_train(x))\n",
        "\n",
        "    print(f'에포크 {epoch:03d} | 평균 손실 >>'\n",
        "          f' 생성자/판별자 {torch.FloatTensor(g_losses).mean():.4f}'\n",
        "          f'/{torch.FloatTensor(d_losses).mean():.4f}')\n",
        "    gen_model.eval()\n",
        "    epoch_samples.append(\n",
        "        create_samples(gen_model, fixed_z).detach().cpu().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "popAigHo5kWu",
        "outputId": "5d286929-f3e4-46ee-9766-721079058a87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에포크 001 | 평균 손실 >> 생성자/판별자 5.0750/0.0856\n",
            "에포크 002 | 평균 손실 >> 생성자/판별자 4.9231/0.1243\n",
            "에포크 003 | 평균 손실 >> 생성자/판별자 3.9919/0.2308\n",
            "에포크 004 | 평균 손실 >> 생성자/판별자 3.1527/0.3175\n",
            "에포크 005 | 평균 손실 >> 생성자/판별자 3.1185/0.2937\n",
            "에포크 006 | 평균 손실 >> 생성자/판별자 2.9826/0.2963\n",
            "에포크 007 | 평균 손실 >> 생성자/판별자 3.0435/0.3099\n",
            "에포크 008 | 평균 손실 >> 생성자/판별자 3.0469/0.3026\n",
            "에포크 009 | 평균 손실 >> 생성자/판별자 3.0169/0.2856\n",
            "에포크 010 | 평균 손실 >> 생성자/판별자 3.1379/0.2836\n",
            "에포크 011 | 평균 손실 >> 생성자/판별자 3.1667/0.2654\n",
            "에포크 012 | 평균 손실 >> 생성자/판별자 3.1919/0.2516\n",
            "에포크 013 | 평균 손실 >> 생성자/판별자 3.2643/0.2369\n",
            "에포크 014 | 평균 손실 >> 생성자/판별자 3.3087/0.2507\n",
            "에포크 015 | 평균 손실 >> 생성자/판별자 3.3580/0.2278\n",
            "에포크 016 | 평균 손실 >> 생성자/판별자 3.3583/0.2484\n",
            "에포크 017 | 평균 손실 >> 생성자/판별자 3.4085/0.2352\n",
            "에포크 018 | 평균 손실 >> 생성자/판별자 3.3736/0.2457\n",
            "에포크 019 | 평균 손실 >> 생성자/판별자 3.5007/0.2160\n",
            "에포크 020 | 평균 손실 >> 생성자/판별자 3.4770/0.2164\n",
            "에포크 021 | 평균 손실 >> 생성자/판별자 3.5242/0.2347\n",
            "에포크 022 | 평균 손실 >> 생성자/판별자 3.5354/0.2170\n",
            "에포크 023 | 평균 손실 >> 생성자/판별자 3.5554/0.2115\n",
            "에포크 024 | 평균 손실 >> 생성자/판별자 3.6500/0.2027\n",
            "에포크 025 | 평균 손실 >> 생성자/판별자 3.6292/0.2208\n",
            "에포크 026 | 평균 손실 >> 생성자/판별자 3.7563/0.1827\n",
            "에포크 027 | 평균 손실 >> 생성자/판별자 3.7461/0.1894\n",
            "에포크 028 | 평균 손실 >> 생성자/판별자 3.7710/0.2013\n",
            "에포크 029 | 평균 손실 >> 생성자/판별자 3.8103/0.2164\n",
            "에포크 030 | 평균 손실 >> 생성자/판별자 3.8277/0.1888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 시각화를 위해서 수집한 변수를 저장하고 불러오기\n",
        "saved_variables = {\n",
        "    'epoch_samples': epoch_samples,\n",
        "    'd_losses': d_losses,\n",
        "    'g_losses': g_losses\n",
        "}\n",
        "torch.save(saved_variables,'/content/drive/MyDrive/saved_variables2,pth')\n",
        "\n",
        "\n",
        "# 판별자 모델\n",
        "torch.save(disc_model,'/content/drive/MyDrive/disc_model2.pth')\n",
        " # 생성자 모델\n",
        "torch.save(gen_model,'/content/drive/MyDrive/gen_model2.pth')"
      ],
      "metadata": {
        "id": "Z7zKDfdS7EPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"device : {device}\")\n",
        "\n",
        "# 불러오기\n",
        "loaded_variables = torch.load('/content/drive/MyDrive/saved_variables2,pth')\n",
        "# 각 변수를 불러오기\n",
        "epoch_samples = loaded_variables['epoch_samples']\n",
        "d_losses = loaded_variables['d_losses']\n",
        "g_losses = loaded_variables['g_losses']\n",
        "# 판별자 생성자 모델 불러오기\n",
        "disc_model = torch.load('/content/drive/MyDrive/disc_model2.pth')\n",
        "gen_model = torch.load('/content/drive/MyDrive/gen_model2.pth')"
      ],
      "metadata": {
        "id": "q4Se88q1CS3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "udWT-EwpC0T1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
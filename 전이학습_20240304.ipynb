{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bdIz13J2_KWW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "전이학습\n",
        "  - 파이썬을 배운사람은 다른언어도 좀더 쉽게 배울수 있음\n",
        "  - 영상관련해서는 데이터를 확보는게 어렵다.. 기존 방대한 데이터로 학습된 모델을 가져와서 이용"
      ],
      "metadata": {
        "id": "gMELrg9N_gHI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ImageNet으로 학습된 ResNet50을 cub 데이터셋으로 전이학습"
      ],
      "metadata": {
        "id": "mSyuUhxlAag_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten,Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import os"
      ],
      "metadata": {
        "id": "6hlzLEoL_5To"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/data/cub200.zip\""
      ],
      "metadata": {
        "id": "W-JreJ1JBMi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob"
      ],
      "metadata": {
        "id": "bhV8ggtTDWtj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_lists = glob(\"/content/CUB_200_2011/images/**/*.jpg\")\n",
        "file_lists[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUjlPaZbEyn7",
        "outputId": "c0611fc1-e93d-475c-9a5d-e81d39a0f35e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/CUB_200_2011/images/145.Elegant_Tern/Elegant_Tern_0005_150708.jpg',\n",
              " '/content/CUB_200_2011/images/145.Elegant_Tern/Elegant_Tern_0084_150922.jpg',\n",
              " '/content/CUB_200_2011/images/145.Elegant_Tern/Elegant_Tern_0066_150864.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_reduce = 0.1\n",
        "no_count = int(len([ fpath.split('/')[4] for fpath in file_lists])*class_reduce)"
      ],
      "metadata": {
        "id": "vfkByGoBE5jy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []; y_train=[]\n",
        "train_file_paths = file_lists[:no_count]\n",
        "temp = np.unique([ i.split('/')[4] for i in train_file_paths])\n",
        "ylabel_dict = dict(zip( temp, list(range(len(temp))) ))\n",
        "ylabel_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_5kSR0WFbhB",
        "outputId": "2000dd46-68eb-49b4-b6c5-4de77b1d18ed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'003.Sooty_Albatross': 0,\n",
              " '013.Bobolink': 1,\n",
              " '021.Eastern_Towhee': 2,\n",
              " '030.Fish_Crow': 3,\n",
              " '052.Pied_billed_Grebe': 4,\n",
              " '065.Slaty_backed_Gull': 5,\n",
              " '067.Anna_Hummingbird': 6,\n",
              " '097.Orchard_Oriole': 7,\n",
              " '100.Brown_Pelican': 8,\n",
              " '116.Chipping_Sparrow': 9,\n",
              " '119.Field_Sparrow': 10,\n",
              " '128.Seaside_Sparrow': 11,\n",
              " '145.Elegant_Tern': 12,\n",
              " '154.Red_eyed_Vireo': 13,\n",
              " '170.Mourning_Warbler': 14,\n",
              " '174.Palm_Warbler': 15,\n",
              " '175.Pine_Warbler': 16,\n",
              " '179.Tennessee_Warbler': 17,\n",
              " '181.Worm_eating_Warbler': 18,\n",
              " '188.Pileated_Woodpecker': 19}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_tests = file_lists[no_count:][:5]  # 119.Field_Sparrow    10\n",
        "x_test,y_test = [],[]\n",
        "for xt in x_tests:\n",
        "  img = image.load_img( xt ,target_size=(224,224))\n",
        "  if len(img.getbands()) != 3:\n",
        "    print(f'유효하지 않은 영상 {xt}')\n",
        "    continue\n",
        "  x = image.img_to_array(img)\n",
        "  x = preprocess_input(x)  # 전이학습 모델의 입력형태로 변경\n",
        "  x_test.append(x)  # 학습용 데이터\n",
        "  y_test.append( ylabel_dict[ xt.split('/')[4] ] )\n",
        "x_test = np.array(x_test); y_test = np.array(y_test)\n",
        "x_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8QUIiKNVy6N",
        "outputId": "af5f5b9d-24d7-4312-b9e1-0c44e775518a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5, 224, 224, 3), (5,))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4Gf9eHvXQPm",
        "outputId": "29e5fd96-947f-407b-de34-6b73c1e02e09"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([10, 10, 10, 10, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,y_train = [],[]\n",
        "for img_file_path in train_file_paths:\n",
        "  img = image.load_img( img_file_path ,target_size=(224,224))\n",
        "  if len(img.getbands()) != 3:\n",
        "    print(f'유효하지 않은 영상 {img_file_path}')\n",
        "    continue\n",
        "  x = image.img_to_array(img)\n",
        "  x = preprocess_input(x)  # 전이학습 모델의 입력형태로 변경\n",
        "  x_train.append(x)  # 학습용 데이터\n",
        "  y_train.append( ylabel_dict[ img_file_path.split('/')[4] ] )\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)"
      ],
      "metadata": {
        "id": "f4MjP26bIFoc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, y_train.shape, y_train[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyrIPldxPM6p",
        "outputId": "a4fe96db-c872-4a50-92ff-78c8e3b4746e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1179, 224, 224, 3), (1179,), array([12, 12, 12, 12, 12]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_class = len(np.unique(y_train))\n",
        "y_train_one_hot = tf.keras.utils.to_categorical(y_train,no_class)\n"
      ],
      "metadata": {
        "id": "s_rK9IrMI2Vk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = ResNet50(include_top=False,input_shape=(224, 224,3))\n",
        "cnn =Sequential()\n",
        "cnn.add(base_model)\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(1024,activation='relu'))\n",
        "cnn.add(Dense(no_class,activation='softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZnGJscANCVJ",
        "outputId": "a62e8818-eaf9-4689-fd17-a44e65d85d74"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.summary()"
      ],
      "metadata": {
        "id": "MkRQbWVuRniG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(loss='categorical_crossentropy', optimizer=Adam(),metrics=['accuracy'])\n",
        "hist = cnn.fit(x_train,y_train_one_hot,epochs = 10)"
      ],
      "metadata": {
        "id": "tceGM3_pP5XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AMQknFNDRZa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQa2qO1bUPSM",
        "outputId": "d7e58106-ed11-493c-aae4-9fed04356236"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       17, 18, 19])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, y_train_one_hot.shape, x_test.shape, y_test.shape\n",
        "# cnn.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhuZklsgVnR4",
        "outputId": "6ce19da6-8cc5-4b54-db10-eb48c73e077b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1179, 224, 224, 3), (1179, 20), (5, 224, 224, 3), (5,))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이미지 제너레이터 사용"
      ],
      "metadata": {
        "id": "KuIAtisSbn3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_data_dir = '/content/CUB_200_2011/images'\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        "    )\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size = (224,224),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'categorical',\n",
        "    subset='training'\n",
        ")\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size = (224,224),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'categorical',\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP0yiXjVYHFy",
        "outputId": "af1f8888-42c5-49bd-828a-c471e2e8e689"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9472 images belonging to 200 classes.\n",
            "Found 2324 images belonging to 200 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_class = 200\n",
        "base_model = ResNet50(include_top=False,input_shape=(224, 224,3))\n",
        "cnn =Sequential()\n",
        "cnn.add(base_model)\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(1024,activation='relu'))\n",
        "cnn.add(Dense(no_class,activation='softmax'))\n",
        "\n",
        "cnn.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(),metrics=['accuracy'] )"
      ],
      "metadata": {
        "id": "6P3rysAocxYc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTxNRryhiud6",
        "outputId": "ec89cbcc-d230-4460-b649-c7b783e5f159"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 100352)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              102761472 \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 200)               205000    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 126554184 (482.77 MB)\n",
            "Trainable params: 126501064 (482.56 MB)\n",
            "Non-trainable params: 53120 (207.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist = cnn.fit(\n",
        "    train_generator,\n",
        "    validation_data = validation_generator,\n",
        "    epochs = 10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYxz9PT7f7he",
        "outputId": "24e86299-302c-4042-b383-a07831676881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QnSdh1VHiUCT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}